{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dogs v Cats super-charged!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/fastai/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# This file contains all the main external libs we'll use\n",
    "from fastai.imports import *\n",
    "\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *\n",
    "\n",
    "PATH = \"/datasets/dogscats/\"\n",
    "# arch=resnet50\n",
    "sz = 299\n",
    "arch = resnext50\n",
    "bs=20\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n",
    "data = ImageClassifierData.from_paths(PATH, tfms=tfms, bs=bs, num_workers=4)\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=True, ps=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3f354efe014d058f6d2c9be90357bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                       \n",
      "    0      0.042245   0.024633   0.9925    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e69bef95f741d48bf8775d0b58c82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                       \n",
      "    0      0.051207   0.021617   0.994     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.fit(1e-2, 1)\n",
    "\n",
    "learn.precompute=False\n",
    "learn.fit(1e-2, 1, cycle_len=1)\n",
    "\n",
    "# learn.unfreeze()\n",
    "# lr=np.array([1e-4,1e-3,1e-2])\n",
    "# learn.fit(lr, 3, cycle_len=1)\n",
    "\n",
    "learn.save('299_all_50')\n",
    "learn.load('299_all_50')\n",
    "\n",
    "# log_preds,y = learn.TTA()\n",
    "# probs = np.mean(np.exp(log_preds),0)\n",
    "\n",
    "# accuracy_np(probs,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# onxx to coreml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.precompute=False\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('299_all_50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from onnx_coreml import convert\n",
    "from torch.autograd import Variable\n",
    "import torch.onnx\n",
    "import torchvision\n",
    "import onnx\n",
    "def check_onnx_compatible(model, model_name, sz, input_names, output_names):\n",
    "    dummy_input = Variable(torch.randn(3, sz, sz)).cuda()\n",
    "\n",
    "    torch.onnx.export(model, dummy_input, \\\n",
    "                      model_name, input_names = input_names, output_names = output_names, verbose=True)\n",
    "    \n",
    "    \n",
    "    # Check again by onnx\n",
    "    # Load the ONNX model\n",
    "    onnx_model = onnx.load(model_name)\n",
    "\n",
    "    # Check that the IR is well formed\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "\n",
    "    # Print a human readable representation of the graph\n",
    "#     onnx.helper.printable_graph(onnx_model.graph)\n",
    "    print(\"Done\")\n",
    "    return onnx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageScale(nn.Module):\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "        self.denorminator = torch.full((3, sz, sz), 255.0, device=torch.device(\"cuda\"))\n",
    "\n",
    "    def forward(self, x): return torch.div(x, self.denorminator).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = [ImageScale()] + (list(learn.model.children())[:-1] + [nn.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = nn.Sequential(*final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%image : Float(3, 299, 299)\n",
      "      %1 : Float(64, 3, 7, 7)\n",
      "      %2 : Float(64)\n",
      "      %3 : Float(64)\n",
      "      %4 : Float(64)\n",
      "      %5 : Float(64)\n",
      "      %6 : Long()\n",
      "      %7 : Float(128, 64, 1, 1)\n",
      "      %8 : Float(128)\n",
      "      %9 : Float(128)\n",
      "      %10 : Float(128)\n",
      "      %11 : Float(128)\n",
      "      %12 : Long()\n",
      "      %13 : Float(128, 4, 3, 3)\n",
      "      %14 : Float(128)\n",
      "      %15 : Float(128)\n",
      "      %16 : Float(128)\n",
      "      %17 : Float(128)\n",
      "      %18 : Long()\n",
      "      %19 : Float(256, 128, 1, 1)\n",
      "      %20 : Float(256)\n",
      "      %21 : Float(256)\n",
      "      %22 : Float(256)\n",
      "      %23 : Float(256)\n",
      "      %24 : Long()\n",
      "      %25 : Float(256, 64, 1, 1)\n",
      "      %26 : Float(256)\n",
      "      %27 : Float(256)\n",
      "      %28 : Float(256)\n",
      "      %29 : Float(256)\n",
      "      %30 : Long()\n",
      "      %31 : Float(128, 256, 1, 1)\n",
      "      %32 : Float(128)\n",
      "      %33 : Float(128)\n",
      "      %34 : Float(128)\n",
      "      %35 : Float(128)\n",
      "      %36 : Long()\n",
      "      %37 : Float(128, 4, 3, 3)\n",
      "      %38 : Float(128)\n",
      "      %39 : Float(128)\n",
      "      %40 : Float(128)\n",
      "      %41 : Float(128)\n",
      "      %42 : Long()\n",
      "      %43 : Float(256, 128, 1, 1)\n",
      "      %44 : Float(256)\n",
      "      %45 : Float(256)\n",
      "      %46 : Float(256)\n",
      "      %47 : Float(256)\n",
      "      %48 : Long()\n",
      "      %49 : Float(128, 256, 1, 1)\n",
      "      %50 : Float(128)\n",
      "      %51 : Float(128)\n",
      "      %52 : Float(128)\n",
      "      %53 : Float(128)\n",
      "      %54 : Long()\n",
      "      %55 : Float(128, 4, 3, 3)\n",
      "      %56 : Float(128)\n",
      "      %57 : Float(128)\n",
      "      %58 : Float(128)\n",
      "      %59 : Float(128)\n",
      "      %60 : Long()\n",
      "      %61 : Float(256, 128, 1, 1)\n",
      "      %62 : Float(256)\n",
      "      %63 : Float(256)\n",
      "      %64 : Float(256)\n",
      "      %65 : Float(256)\n",
      "      %66 : Long()\n",
      "      %67 : Float(256, 256, 1, 1)\n",
      "      %68 : Float(256)\n",
      "      %69 : Float(256)\n",
      "      %70 : Float(256)\n",
      "      %71 : Float(256)\n",
      "      %72 : Long()\n",
      "      %73 : Float(256, 8, 3, 3)\n",
      "      %74 : Float(256)\n",
      "      %75 : Float(256)\n",
      "      %76 : Float(256)\n",
      "      %77 : Float(256)\n",
      "      %78 : Long()\n",
      "      %79 : Float(512, 256, 1, 1)\n",
      "      %80 : Float(512)\n",
      "      %81 : Float(512)\n",
      "      %82 : Float(512)\n",
      "      %83 : Float(512)\n",
      "      %84 : Long()\n",
      "      %85 : Float(512, 256, 1, 1)\n",
      "      %86 : Float(512)\n",
      "      %87 : Float(512)\n",
      "      %88 : Float(512)\n",
      "      %89 : Float(512)\n",
      "      %90 : Long()\n",
      "      %91 : Float(256, 512, 1, 1)\n",
      "      %92 : Float(256)\n",
      "      %93 : Float(256)\n",
      "      %94 : Float(256)\n",
      "      %95 : Float(256)\n",
      "      %96 : Long()\n",
      "      %97 : Float(256, 8, 3, 3)\n",
      "      %98 : Float(256)\n",
      "      %99 : Float(256)\n",
      "      %100 : Float(256)\n",
      "      %101 : Float(256)\n",
      "      %102 : Long()\n",
      "      %103 : Float(512, 256, 1, 1)\n",
      "      %104 : Float(512)\n",
      "      %105 : Float(512)\n",
      "      %106 : Float(512)\n",
      "      %107 : Float(512)\n",
      "      %108 : Long()\n",
      "      %109 : Float(256, 512, 1, 1)\n",
      "      %110 : Float(256)\n",
      "      %111 : Float(256)\n",
      "      %112 : Float(256)\n",
      "      %113 : Float(256)\n",
      "      %114 : Long()\n",
      "      %115 : Float(256, 8, 3, 3)\n",
      "      %116 : Float(256)\n",
      "      %117 : Float(256)\n",
      "      %118 : Float(256)\n",
      "      %119 : Float(256)\n",
      "      %120 : Long()\n",
      "      %121 : Float(512, 256, 1, 1)\n",
      "      %122 : Float(512)\n",
      "      %123 : Float(512)\n",
      "      %124 : Float(512)\n",
      "      %125 : Float(512)\n",
      "      %126 : Long()\n",
      "      %127 : Float(256, 512, 1, 1)\n",
      "      %128 : Float(256)\n",
      "      %129 : Float(256)\n",
      "      %130 : Float(256)\n",
      "      %131 : Float(256)\n",
      "      %132 : Long()\n",
      "      %133 : Float(256, 8, 3, 3)\n",
      "      %134 : Float(256)\n",
      "      %135 : Float(256)\n",
      "      %136 : Float(256)\n",
      "      %137 : Float(256)\n",
      "      %138 : Long()\n",
      "      %139 : Float(512, 256, 1, 1)\n",
      "      %140 : Float(512)\n",
      "      %141 : Float(512)\n",
      "      %142 : Float(512)\n",
      "      %143 : Float(512)\n",
      "      %144 : Long()\n",
      "      %145 : Float(512, 512, 1, 1)\n",
      "      %146 : Float(512)\n",
      "      %147 : Float(512)\n",
      "      %148 : Float(512)\n",
      "      %149 : Float(512)\n",
      "      %150 : Long()\n",
      "      %151 : Float(512, 16, 3, 3)\n",
      "      %152 : Float(512)\n",
      "      %153 : Float(512)\n",
      "      %154 : Float(512)\n",
      "      %155 : Float(512)\n",
      "      %156 : Long()\n",
      "      %157 : Float(1024, 512, 1, 1)\n",
      "      %158 : Float(1024)\n",
      "      %159 : Float(1024)\n",
      "      %160 : Float(1024)\n",
      "      %161 : Float(1024)\n",
      "      %162 : Long()\n",
      "      %163 : Float(1024, 512, 1, 1)\n",
      "      %164 : Float(1024)\n",
      "      %165 : Float(1024)\n",
      "      %166 : Float(1024)\n",
      "      %167 : Float(1024)\n",
      "      %168 : Long()\n",
      "      %169 : Float(512, 1024, 1, 1)\n",
      "      %170 : Float(512)\n",
      "      %171 : Float(512)\n",
      "      %172 : Float(512)\n",
      "      %173 : Float(512)\n",
      "      %174 : Long()\n",
      "      %175 : Float(512, 16, 3, 3)\n",
      "      %176 : Float(512)\n",
      "      %177 : Float(512)\n",
      "      %178 : Float(512)\n",
      "      %179 : Float(512)\n",
      "      %180 : Long()\n",
      "      %181 : Float(1024, 512, 1, 1)\n",
      "      %182 : Float(1024)\n",
      "      %183 : Float(1024)\n",
      "      %184 : Float(1024)\n",
      "      %185 : Float(1024)\n",
      "      %186 : Long()\n",
      "      %187 : Float(512, 1024, 1, 1)\n",
      "      %188 : Float(512)\n",
      "      %189 : Float(512)\n",
      "      %190 : Float(512)\n",
      "      %191 : Float(512)\n",
      "      %192 : Long()\n",
      "      %193 : Float(512, 16, 3, 3)\n",
      "      %194 : Float(512)\n",
      "      %195 : Float(512)\n",
      "      %196 : Float(512)\n",
      "      %197 : Float(512)\n",
      "      %198 : Long()\n",
      "      %199 : Float(1024, 512, 1, 1)\n",
      "      %200 : Float(1024)\n",
      "      %201 : Float(1024)\n",
      "      %202 : Float(1024)\n",
      "      %203 : Float(1024)\n",
      "      %204 : Long()\n",
      "      %205 : Float(512, 1024, 1, 1)\n",
      "      %206 : Float(512)\n",
      "      %207 : Float(512)\n",
      "      %208 : Float(512)\n",
      "      %209 : Float(512)\n",
      "      %210 : Long()\n",
      "      %211 : Float(512, 16, 3, 3)\n",
      "      %212 : Float(512)\n",
      "      %213 : Float(512)\n",
      "      %214 : Float(512)\n",
      "      %215 : Float(512)\n",
      "      %216 : Long()\n",
      "      %217 : Float(1024, 512, 1, 1)\n",
      "      %218 : Float(1024)\n",
      "      %219 : Float(1024)\n",
      "      %220 : Float(1024)\n",
      "      %221 : Float(1024)\n",
      "      %222 : Long()\n",
      "      %223 : Float(512, 1024, 1, 1)\n",
      "      %224 : Float(512)\n",
      "      %225 : Float(512)\n",
      "      %226 : Float(512)\n",
      "      %227 : Float(512)\n",
      "      %228 : Long()\n",
      "      %229 : Float(512, 16, 3, 3)\n",
      "      %230 : Float(512)\n",
      "      %231 : Float(512)\n",
      "      %232 : Float(512)\n",
      "      %233 : Float(512)\n",
      "      %234 : Long()\n",
      "      %235 : Float(1024, 512, 1, 1)\n",
      "      %236 : Float(1024)\n",
      "      %237 : Float(1024)\n",
      "      %238 : Float(1024)\n",
      "      %239 : Float(1024)\n",
      "      %240 : Long()\n",
      "      %241 : Float(512, 1024, 1, 1)\n",
      "      %242 : Float(512)\n",
      "      %243 : Float(512)\n",
      "      %244 : Float(512)\n",
      "      %245 : Float(512)\n",
      "      %246 : Long()\n",
      "      %247 : Float(512, 16, 3, 3)\n",
      "      %248 : Float(512)\n",
      "      %249 : Float(512)\n",
      "      %250 : Float(512)\n",
      "      %251 : Float(512)\n",
      "      %252 : Long()\n",
      "      %253 : Float(1024, 512, 1, 1)\n",
      "      %254 : Float(1024)\n",
      "      %255 : Float(1024)\n",
      "      %256 : Float(1024)\n",
      "      %257 : Float(1024)\n",
      "      %258 : Long()\n",
      "      %259 : Float(1024, 1024, 1, 1)\n",
      "      %260 : Float(1024)\n",
      "      %261 : Float(1024)\n",
      "      %262 : Float(1024)\n",
      "      %263 : Float(1024)\n",
      "      %264 : Long()\n",
      "      %265 : Float(1024, 32, 3, 3)\n",
      "      %266 : Float(1024)\n",
      "      %267 : Float(1024)\n",
      "      %268 : Float(1024)\n",
      "      %269 : Float(1024)\n",
      "      %270 : Long()\n",
      "      %271 : Float(2048, 1024, 1, 1)\n",
      "      %272 : Float(2048)\n",
      "      %273 : Float(2048)\n",
      "      %274 : Float(2048)\n",
      "      %275 : Float(2048)\n",
      "      %276 : Long()\n",
      "      %277 : Float(2048, 1024, 1, 1)\n",
      "      %278 : Float(2048)\n",
      "      %279 : Float(2048)\n",
      "      %280 : Float(2048)\n",
      "      %281 : Float(2048)\n",
      "      %282 : Long()\n",
      "      %283 : Float(1024, 2048, 1, 1)\n",
      "      %284 : Float(1024)\n",
      "      %285 : Float(1024)\n",
      "      %286 : Float(1024)\n",
      "      %287 : Float(1024)\n",
      "      %288 : Long()\n",
      "      %289 : Float(1024, 32, 3, 3)\n",
      "      %290 : Float(1024)\n",
      "      %291 : Float(1024)\n",
      "      %292 : Float(1024)\n",
      "      %293 : Float(1024)\n",
      "      %294 : Long()\n",
      "      %295 : Float(2048, 1024, 1, 1)\n",
      "      %296 : Float(2048)\n",
      "      %297 : Float(2048)\n",
      "      %298 : Float(2048)\n",
      "      %299 : Float(2048)\n",
      "      %300 : Long()\n",
      "      %301 : Float(1024, 2048, 1, 1)\n",
      "      %302 : Float(1024)\n",
      "      %303 : Float(1024)\n",
      "      %304 : Float(1024)\n",
      "      %305 : Float(1024)\n",
      "      %306 : Long()\n",
      "      %307 : Float(1024, 32, 3, 3)\n",
      "      %308 : Float(1024)\n",
      "      %309 : Float(1024)\n",
      "      %310 : Float(1024)\n",
      "      %311 : Float(1024)\n",
      "      %312 : Long()\n",
      "      %313 : Float(2048, 1024, 1, 1)\n",
      "      %314 : Float(2048)\n",
      "      %315 : Float(2048)\n",
      "      %316 : Float(2048)\n",
      "      %317 : Float(2048)\n",
      "      %318 : Long()\n",
      "      %319 : Float(4096)\n",
      "      %320 : Float(4096)\n",
      "      %321 : Float(4096)\n",
      "      %322 : Float(4096)\n",
      "      %323 : Long()\n",
      "      %324 : Float(512, 4096)\n",
      "      %325 : Float(512)\n",
      "      %326 : Float(512)\n",
      "      %327 : Float(512)\n",
      "      %328 : Float(512)\n",
      "      %329 : Float(512)\n",
      "      %330 : Long()\n",
      "      %331 : Float(2, 512)\n",
      "      %332 : Float(2)) {\n",
      "  %333 : Float(3, 299, 299) = onnx::Constant[value=<Tensor>](), scope: Sequential/ImageScale[0]\n",
      "  %334 : Float(3, 299, 299) = onnx::Div(%image, %333), scope: Sequential/ImageScale[0]\n",
      "  %335 : Float(1, 3, 299, 299) = onnx::Unsqueeze[axes=[0]](%334), scope: Sequential/ImageScale[0]\n",
      "  %336 : Float(1, 64, 150, 150) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[2, 2]](%335, %1), scope: Sequential/Conv2d[1]\n",
      "  %337 : Float(1, 64, 150, 150) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%336, %2, %3, %4, %5), scope: Sequential/BatchNorm2d[2]\n",
      "  %338 : Float(1, 64, 150, 150) = onnx::Relu(%337), scope: Sequential/ReLU[3]\n",
      "  %339 : Float(1, 64, 75, 75) = onnx::MaxPool[kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%338), scope: Sequential/MaxPool2d[4]\n",
      "  %340 : Float(1, 128, 75, 75) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%339, %7), scope: Sequential/Sequential[5]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[0]\n",
      "  %341 : Float(1, 128, 75, 75) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%340, %8, %9, %10, %11), scope: Sequential/Sequential[5]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[1]\n",
      "  %342 : Float(1, 128, 75, 75) = onnx::Relu(%341), scope: Sequential/Sequential[5]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[2]\n",
      "  %343 : Float(1, 128, 75, 75) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%342, %13), scope: Sequential/Sequential[5]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[3]\n",
      "  %344 : Float(1, 128, 75, 75) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%343, %14, %15, %16, %17), scope: Sequential/Sequential[5]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[4]\n",
      "  %345 : Float(1, 128, 75, 75) = onnx::Relu(%344), scope: Sequential/Sequential[5]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[5]\n",
      "  %346 : Float(1, 256, 75, 75) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%345, %19), scope: Sequential/Sequential[5]/Sequential[0]/LambdaMap[0]/Sequential[0]/Conv2d[1]\n",
      "  %347 : Float(1, 256, 75, 75) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%346, %20, %21, %22, %23), scope: Sequential/Sequential[5]/Sequential[0]/LambdaMap[0]/Sequential[0]/BatchNorm2d[2]\n",
      "  %348 : Float(1, 256, 75, 75) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%339, %25), scope: Sequential/Sequential[5]/Sequential[0]/LambdaMap[0]/Sequential[1]/Conv2d[0]\n",
      "  %349 : Float(1, 256, 75, 75) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%348, %26, %27, %28, %29), scope: Sequential/Sequential[5]/Sequential[0]/LambdaMap[0]/Sequential[1]/BatchNorm2d[1]\n",
      "  %350 : Float(1, 256, 75, 75) = onnx::Add(%347, %349), scope: Sequential/Sequential[5]/Sequential[0]/LambdaReduce[1]\n",
      "  %351 : Float(1, 256, 75, 75) = onnx::Relu(%350), scope: Sequential/Sequential[5]/Sequential[0]/ReLU[2]\n",
      "  %352 : Float(1, 128, 75, 75) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%351, %31), scope: Sequential/Sequential[5]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[0]\n",
      "  %353 : Float(1, 128, 75, 75) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%352, %32, %33, %34, %35), scope: Sequential/Sequential[5]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[1]\n",
      "  %354 : Float(1, 128, 75, 75) = onnx::Relu(%353), scope: Sequential/Sequential[5]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[2]\n",
      "  %355 : Float(1, 128, 75, 75) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%354, %37), scope: Sequential/Sequential[5]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[3]\n",
      "  %356 : Float(1, 128, 75, 75) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%355, %38, %39, %40, %41), scope: Sequential/Sequential[5]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[4]\n",
      "  %357 : Float(1, 128, 75, 75) = onnx::Relu(%356), scope: Sequential/Sequential[5]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[5]\n",
      "  %358 : Float(1, 256, 75, 75) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%357, %43), scope: Sequential/Sequential[5]/Sequential[1]/LambdaMap[0]/Sequential[0]/Conv2d[1]\n",
      "  %359 : Float(1, 256, 75, 75) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%358, %44, %45, %46, %47), scope: Sequential/Sequential[5]/Sequential[1]/LambdaMap[0]/Sequential[0]/BatchNorm2d[2]\n",
      "  %360 : Float(1, 256, 75, 75) = onnx::Add(%359, %351), scope: Sequential/Sequential[5]/Sequential[1]/LambdaReduce[1]\n",
      "  %361 : Float(1, 256, 75, 75) = onnx::Relu(%360), scope: Sequential/Sequential[5]/Sequential[1]/ReLU[2]\n",
      "  %362 : Float(1, 128, 75, 75) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%361, %49), scope: Sequential/Sequential[5]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[0]\n",
      "  %363 : Float(1, 128, 75, 75) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%362, %50, %51, %52, %53), scope: Sequential/Sequential[5]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[1]\n",
      "  %364 : Float(1, 128, 75, 75) = onnx::Relu(%363), scope: Sequential/Sequential[5]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[2]\n",
      "  %365 : Float(1, 128, 75, 75) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%364, %55), scope: Sequential/Sequential[5]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[3]\n",
      "  %366 : Float(1, 128, 75, 75) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%365, %56, %57, %58, %59), scope: Sequential/Sequential[5]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[4]\n",
      "  %367 : Float(1, 128, 75, 75) = onnx::Relu(%366), scope: Sequential/Sequential[5]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[5]\n",
      "  %368 : Float(1, 256, 75, 75) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%367, %61), scope: Sequential/Sequential[5]/Sequential[2]/LambdaMap[0]/Sequential[0]/Conv2d[1]\n",
      "  %369 : Float(1, 256, 75, 75) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%368, %62, %63, %64, %65), scope: Sequential/Sequential[5]/Sequential[2]/LambdaMap[0]/Sequential[0]/BatchNorm2d[2]\n",
      "  %370 : Float(1, 256, 75, 75) = onnx::Add(%369, %361), scope: Sequential/Sequential[5]/Sequential[2]/LambdaReduce[1]\n",
      "  %371 : Float(1, 256, 75, 75) = onnx::Relu(%370), scope: Sequential/Sequential[5]/Sequential[2]/ReLU[2]\n",
      "  %372 : Float(1, 256, 75, 75) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%371, %67), scope: Sequential/Sequential[6]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[0]\n",
      "  %373 : Float(1, 256, 75, 75) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%372, %68, %69, %70, %71), scope: Sequential/Sequential[6]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[1]\n",
      "  %374 : Float(1, 256, 75, 75) = onnx::Relu(%373), scope: Sequential/Sequential[6]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[2]\n",
      "  %375 : Float(1, 256, 38, 38) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%374, %73), scope: Sequential/Sequential[6]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[3]\n",
      "  %376 : Float(1, 256, 38, 38) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%375, %74, %75, %76, %77), scope: Sequential/Sequential[6]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[4]\n",
      "  %377 : Float(1, 256, 38, 38) = onnx::Relu(%376), scope: Sequential/Sequential[6]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[5]\n",
      "  %378 : Float(1, 512, 38, 38) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%377, %79), scope: Sequential/Sequential[6]/Sequential[0]/LambdaMap[0]/Sequential[0]/Conv2d[1]\n",
      "  %379 : Float(1, 512, 38, 38) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%378, %80, %81, %82, %83), scope: Sequential/Sequential[6]/Sequential[0]/LambdaMap[0]/Sequential[0]/BatchNorm2d[2]\n",
      "  %380 : Float(1, 512, 38, 38) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%371, %85), scope: Sequential/Sequential[6]/Sequential[0]/LambdaMap[0]/Sequential[1]/Conv2d[0]\n",
      "  %381 : Float(1, 512, 38, 38) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%380, %86, %87, %88, %89), scope: Sequential/Sequential[6]/Sequential[0]/LambdaMap[0]/Sequential[1]/BatchNorm2d[1]\n",
      "  %382 : Float(1, 512, 38, 38) = onnx::Add(%379, %381), scope: Sequential/Sequential[6]/Sequential[0]/LambdaReduce[1]\n",
      "  %383 : Float(1, 512, 38, 38) = onnx::Relu(%382), scope: Sequential/Sequential[6]/Sequential[0]/ReLU[2]\n",
      "  %384 : Float(1, 256, 38, 38) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%383, %91), scope: Sequential/Sequential[6]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[0]\n",
      "  %385 : Float(1, 256, 38, 38) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%384, %92, %93, %94, %95), scope: Sequential/Sequential[6]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[1]\n",
      "  %386 : Float(1, 256, 38, 38) = onnx::Relu(%385), scope: Sequential/Sequential[6]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[2]\n",
      "  %387 : Float(1, 256, 38, 38) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%386, %97), scope: Sequential/Sequential[6]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[3]\n",
      "  %388 : Float(1, 256, 38, 38) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%387, %98, %99, %100, %101), scope: Sequential/Sequential[6]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[4]\n",
      "  %389 : Float(1, 256, 38, 38) = onnx::Relu(%388), scope: Sequential/Sequential[6]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[5]\n",
      "  %390 : Float(1, 512, 38, 38) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%389, %103), scope: Sequential/Sequential[6]/Sequential[1]/LambdaMap[0]/Sequential[0]/Conv2d[1]\n",
      "  %391 : Float(1, 512, 38, 38) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%390, %104, %105, %106, %107), scope: Sequential/Sequential[6]/Sequential[1]/LambdaMap[0]/Sequential[0]/BatchNorm2d[2]\n",
      "  %392 : Float(1, 512, 38, 38) = onnx::Add(%391, %383), scope: Sequential/Sequential[6]/Sequential[1]/LambdaReduce[1]\n",
      "  %393 : Float(1, 512, 38, 38) = onnx::Relu(%392), scope: Sequential/Sequential[6]/Sequential[1]/ReLU[2]\n",
      "  %394 : Float(1, 256, 38, 38) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%393, %109), scope: Sequential/Sequential[6]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[0]\n",
      "  %395 : Float(1, 256, 38, 38) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%394, %110, %111, %112, %113), scope: Sequential/Sequential[6]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[1]\n",
      "  %396 : Float(1, 256, 38, 38) = onnx::Relu(%395), scope: Sequential/Sequential[6]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[2]\n",
      "  %397 : Float(1, 256, 38, 38) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%396, %115), scope: Sequential/Sequential[6]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[3]\n",
      "  %398 : Float(1, 256, 38, 38) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%397, %116, %117, %118, %119), scope: Sequential/Sequential[6]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[4]\n",
      "  %399 : Float(1, 256, 38, 38) = onnx::Relu(%398), scope: Sequential/Sequential[6]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[5]\n",
      "  %400 : Float(1, 512, 38, 38) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%399, %121), scope: Sequential/Sequential[6]/Sequential[2]/LambdaMap[0]/Sequential[0]/Conv2d[1]\n",
      "  %401 : Float(1, 512, 38, 38) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%400, %122, %123, %124, %125), scope: Sequential/Sequential[6]/Sequential[2]/LambdaMap[0]/Sequential[0]/BatchNorm2d[2]\n",
      "  %402 : Float(1, 512, 38, 38) = onnx::Add(%401, %393), scope: Sequential/Sequential[6]/Sequential[2]/LambdaReduce[1]\n",
      "  %403 : Float(1, 512, 38, 38) = onnx::Relu(%402), scope: Sequential/Sequential[6]/Sequential[2]/ReLU[2]\n",
      "  %404 : Float(1, 256, 38, 38) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%403, %127), scope: Sequential/Sequential[6]/Sequential[3]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[0]\n",
      "  %405 : Float(1, 256, 38, 38) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%404, %128, %129, %130, %131), scope: Sequential/Sequential[6]/Sequential[3]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[1]\n",
      "  %406 : Float(1, 256, 38, 38) = onnx::Relu(%405), scope: Sequential/Sequential[6]/Sequential[3]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[2]\n",
      "  %407 : Float(1, 256, 38, 38) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%406, %133), scope: Sequential/Sequential[6]/Sequential[3]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[3]\n",
      "  %408 : Float(1, 256, 38, 38) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%407, %134, %135, %136, %137), scope: Sequential/Sequential[6]/Sequential[3]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[4]\n",
      "  %409 : Float(1, 256, 38, 38) = onnx::Relu(%408), scope: Sequential/Sequential[6]/Sequential[3]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[5]\n",
      "  %410 : Float(1, 512, 38, 38) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%409, %139), scope: Sequential/Sequential[6]/Sequential[3]/LambdaMap[0]/Sequential[0]/Conv2d[1]\n",
      "  %411 : Float(1, 512, 38, 38) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%410, %140, %141, %142, %143), scope: Sequential/Sequential[6]/Sequential[3]/LambdaMap[0]/Sequential[0]/BatchNorm2d[2]\n",
      "  %412 : Float(1, 512, 38, 38) = onnx::Add(%411, %403), scope: Sequential/Sequential[6]/Sequential[3]/LambdaReduce[1]\n",
      "  %413 : Float(1, 512, 38, 38) = onnx::Relu(%412), scope: Sequential/Sequential[6]/Sequential[3]/ReLU[2]\n",
      "  %414 : Float(1, 512, 38, 38) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%413, %145), scope: Sequential/Sequential[7]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[0]\n",
      "  %415 : Float(1, 512, 38, 38) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%414, %146, %147, %148, %149), scope: Sequential/Sequential[7]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[1]\n",
      "  %416 : Float(1, 512, 38, 38) = onnx::Relu(%415), scope: Sequential/Sequential[7]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[2]\n",
      "  %417 : Float(1, 512, 19, 19) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%416, %151), scope: Sequential/Sequential[7]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[3]\n",
      "  %418 : Float(1, 512, 19, 19) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%417, %152, %153, %154, %155), scope: Sequential/Sequential[7]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[4]\n",
      "  %419 : Float(1, 512, 19, 19) = onnx::Relu(%418), scope: Sequential/Sequential[7]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[5]\n",
      "  %420 : Float(1, 1024, 19, 19) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%419, %157), scope: Sequential/Sequential[7]/Sequential[0]/LambdaMap[0]/Sequential[0]/Conv2d[1]\n",
      "  %421 : Float(1, 1024, 19, 19) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%420, %158, %159, %160, %161), scope: Sequential/Sequential[7]/Sequential[0]/LambdaMap[0]/Sequential[0]/BatchNorm2d[2]\n",
      "  %422 : Float(1, 1024, 19, 19) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%413, %163), scope: Sequential/Sequential[7]/Sequential[0]/LambdaMap[0]/Sequential[1]/Conv2d[0]\n",
      "  %423 : Float(1, 1024, 19, 19) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%422, %164, %165, %166, %167), scope: Sequential/Sequential[7]/Sequential[0]/LambdaMap[0]/Sequential[1]/BatchNorm2d[1]\n",
      "  %424 : Float(1, 1024, 19, 19) = onnx::Add(%421, %423), scope: Sequential/Sequential[7]/Sequential[0]/LambdaReduce[1]\n",
      "  %425 : Float(1, 1024, 19, 19) = onnx::Relu(%424), scope: Sequential/Sequential[7]/Sequential[0]/ReLU[2]\n",
      "  %426 : Float(1, 512, 19, 19) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%425, %169), scope: Sequential/Sequential[7]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[0]\n",
      "  %427 : Float(1, 512, 19, 19) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%426, %170, %171, %172, %173), scope: Sequential/Sequential[7]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[1]\n",
      "  %428 : Float(1, 512, 19, 19) = onnx::Relu(%427), scope: Sequential/Sequential[7]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[2]\n",
      "  %429 : Float(1, 512, 19, 19) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%428, %175), scope: Sequential/Sequential[7]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[3]\n",
      "  %430 : Float(1, 512, 19, 19) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%429, %176, %177, %178, %179), scope: Sequential/Sequential[7]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[4]\n",
      "  %431 : Float(1, 512, 19, 19) = onnx::Relu(%430), scope: Sequential/Sequential[7]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[5]\n",
      "  %432 : Float(1, 1024, 19, 19) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%431, %181), scope: Sequential/Sequential[7]/Sequential[1]/LambdaMap[0]/Sequential[0]/Conv2d[1]\n",
      "  %433 : Float(1, 1024, 19, 19) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%432, %182, %183, %184, %185), scope: Sequential/Sequential[7]/Sequential[1]/LambdaMap[0]/Sequential[0]/BatchNorm2d[2]\n",
      "  %434 : Float(1, 1024, 19, 19) = onnx::Add(%433, %425), scope: Sequential/Sequential[7]/Sequential[1]/LambdaReduce[1]\n",
      "  %435 : Float(1, 1024, 19, 19) = onnx::Relu(%434), scope: Sequential/Sequential[7]/Sequential[1]/ReLU[2]\n",
      "  %436 : Float(1, 512, 19, 19) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%435, %187), scope: Sequential/Sequential[7]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[0]\n",
      "  %437 : Float(1, 512, 19, 19) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%436, %188, %189, %190, %191), scope: Sequential/Sequential[7]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[1]\n",
      "  %438 : Float(1, 512, 19, 19) = onnx::Relu(%437), scope: Sequential/Sequential[7]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[2]\n",
      "  %439 : Float(1, 512, 19, 19) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%438, %193), scope: Sequential/Sequential[7]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[3]\n",
      "  %440 : Float(1, 512, 19, 19) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%439, %194, %195, %196, %197), scope: Sequential/Sequential[7]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[4]\n",
      "  %441 : Float(1, 512, 19, 19) = onnx::Relu(%440), scope: Sequential/Sequential[7]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[5]\n",
      "  %442 : Float(1, 1024, 19, 19) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%441, %199), scope: Sequential/Sequential[7]/Sequential[2]/LambdaMap[0]/Sequential[0]/Conv2d[1]\n",
      "  %443 : Float(1, 1024, 19, 19) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%442, %200, %201, %202, %203), scope: Sequential/Sequential[7]/Sequential[2]/LambdaMap[0]/Sequential[0]/BatchNorm2d[2]\n",
      "  %444 : Float(1, 1024, 19, 19) = onnx::Add(%443, %435), scope: Sequential/Sequential[7]/Sequential[2]/LambdaReduce[1]\n",
      "  %445 : Float(1, 1024, 19, 19) = onnx::Relu(%444), scope: Sequential/Sequential[7]/Sequential[2]/ReLU[2]\n",
      "  %446 : Float(1, 512, 19, 19) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%445, %205), scope: Sequential/Sequential[7]/Sequential[3]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[0]\n",
      "  %447 : Float(1, 512, 19, 19) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%446, %206, %207, %208, %209), scope: Sequential/Sequential[7]/Sequential[3]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[1]\n",
      "  %448 : Float(1, 512, 19, 19) = onnx::Relu(%447), scope: Sequential/Sequential[7]/Sequential[3]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[2]\n",
      "  %449 : Float(1, 512, 19, 19) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%448, %211), scope: Sequential/Sequential[7]/Sequential[3]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[3]\n",
      "  %450 : Float(1, 512, 19, 19) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%449, %212, %213, %214, %215), scope: Sequential/Sequential[7]/Sequential[3]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[4]\n",
      "  %451 : Float(1, 512, 19, 19) = onnx::Relu(%450), scope: Sequential/Sequential[7]/Sequential[3]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[5]\n",
      "  %452 : Float(1, 1024, 19, 19) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%451, %217), scope: Sequential/Sequential[7]/Sequential[3]/LambdaMap[0]/Sequential[0]/Conv2d[1]\n",
      "  %453 : Float(1, 1024, 19, 19) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%452, %218, %219, %220, %221), scope: Sequential/Sequential[7]/Sequential[3]/LambdaMap[0]/Sequential[0]/BatchNorm2d[2]\n",
      "  %454 : Float(1, 1024, 19, 19) = onnx::Add(%453, %445), scope: Sequential/Sequential[7]/Sequential[3]/LambdaReduce[1]\n",
      "  %455 : Float(1, 1024, 19, 19) = onnx::Relu(%454), scope: Sequential/Sequential[7]/Sequential[3]/ReLU[2]\n",
      "  %456 : Float(1, 512, 19, 19) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%455, %223), scope: Sequential/Sequential[7]/Sequential[4]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[0]\n",
      "  %457 : Float(1, 512, 19, 19) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%456, %224, %225, %226, %227), scope: Sequential/Sequential[7]/Sequential[4]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[1]\n",
      "  %458 : Float(1, 512, 19, 19) = onnx::Relu(%457), scope: Sequential/Sequential[7]/Sequential[4]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[2]\n",
      "  %459 : Float(1, 512, 19, 19) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%458, %229), scope: Sequential/Sequential[7]/Sequential[4]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[3]\n",
      "  %460 : Float(1, 512, 19, 19) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%459, %230, %231, %232, %233), scope: Sequential/Sequential[7]/Sequential[4]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[4]\n",
      "  %461 : Float(1, 512, 19, 19) = onnx::Relu(%460), scope: Sequential/Sequential[7]/Sequential[4]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[5]\n",
      "  %462 : Float(1, 1024, 19, 19) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%461, %235), scope: Sequential/Sequential[7]/Sequential[4]/LambdaMap[0]/Sequential[0]/Conv2d[1]\n",
      "  %463 : Float(1, 1024, 19, 19) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%462, %236, %237, %238, %239), scope: Sequential/Sequential[7]/Sequential[4]/LambdaMap[0]/Sequential[0]/BatchNorm2d[2]\n",
      "  %464 : Float(1, 1024, 19, 19) = onnx::Add(%463, %455), scope: Sequential/Sequential[7]/Sequential[4]/LambdaReduce[1]\n",
      "  %465 : Float(1, 1024, 19, 19) = onnx::Relu(%464), scope: Sequential/Sequential[7]/Sequential[4]/ReLU[2]\n",
      "  %466 : Float(1, 512, 19, 19) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%465, %241), scope: Sequential/Sequential[7]/Sequential[5]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[0]\n",
      "  %467 : Float(1, 512, 19, 19) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%466, %242, %243, %244, %245), scope: Sequential/Sequential[7]/Sequential[5]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[1]\n",
      "  %468 : Float(1, 512, 19, 19) = onnx::Relu(%467), scope: Sequential/Sequential[7]/Sequential[5]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[2]\n",
      "  %469 : Float(1, 512, 19, 19) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%468, %247), scope: Sequential/Sequential[7]/Sequential[5]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[3]\n",
      "  %470 : Float(1, 512, 19, 19) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%469, %248, %249, %250, %251), scope: Sequential/Sequential[7]/Sequential[5]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[4]\n",
      "  %471 : Float(1, 512, 19, 19) = onnx::Relu(%470), scope: Sequential/Sequential[7]/Sequential[5]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[5]\n",
      "  %472 : Float(1, 1024, 19, 19) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%471, %253), scope: Sequential/Sequential[7]/Sequential[5]/LambdaMap[0]/Sequential[0]/Conv2d[1]\n",
      "  %473 : Float(1, 1024, 19, 19) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%472, %254, %255, %256, %257), scope: Sequential/Sequential[7]/Sequential[5]/LambdaMap[0]/Sequential[0]/BatchNorm2d[2]\n",
      "  %474 : Float(1, 1024, 19, 19) = onnx::Add(%473, %465), scope: Sequential/Sequential[7]/Sequential[5]/LambdaReduce[1]\n",
      "  %475 : Float(1, 1024, 19, 19) = onnx::Relu(%474), scope: Sequential/Sequential[7]/Sequential[5]/ReLU[2]\n",
      "  %476 : Float(1, 1024, 19, 19) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%475, %259), scope: Sequential/Sequential[8]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[0]\n",
      "  %477 : Float(1, 1024, 19, 19) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%476, %260, %261, %262, %263), scope: Sequential/Sequential[8]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[1]\n",
      "  %478 : Float(1, 1024, 19, 19) = onnx::Relu(%477), scope: Sequential/Sequential[8]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[2]\n",
      "  %479 : Float(1, 1024, 10, 10) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%478, %265), scope: Sequential/Sequential[8]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[3]\n",
      "  %480 : Float(1, 1024, 10, 10) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%479, %266, %267, %268, %269), scope: Sequential/Sequential[8]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[4]\n",
      "  %481 : Float(1, 1024, 10, 10) = onnx::Relu(%480), scope: Sequential/Sequential[8]/Sequential[0]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[5]\n",
      "  %482 : Float(1, 2048, 10, 10) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%481, %271), scope: Sequential/Sequential[8]/Sequential[0]/LambdaMap[0]/Sequential[0]/Conv2d[1]\n",
      "  %483 : Float(1, 2048, 10, 10) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%482, %272, %273, %274, %275), scope: Sequential/Sequential[8]/Sequential[0]/LambdaMap[0]/Sequential[0]/BatchNorm2d[2]\n",
      "  %484 : Float(1, 2048, 10, 10) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%475, %277), scope: Sequential/Sequential[8]/Sequential[0]/LambdaMap[0]/Sequential[1]/Conv2d[0]\n",
      "  %485 : Float(1, 2048, 10, 10) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%484, %278, %279, %280, %281), scope: Sequential/Sequential[8]/Sequential[0]/LambdaMap[0]/Sequential[1]/BatchNorm2d[1]\n",
      "  %486 : Float(1, 2048, 10, 10) = onnx::Add(%483, %485), scope: Sequential/Sequential[8]/Sequential[0]/LambdaReduce[1]\n",
      "  %487 : Float(1, 2048, 10, 10) = onnx::Relu(%486), scope: Sequential/Sequential[8]/Sequential[0]/ReLU[2]\n",
      "  %488 : Float(1, 1024, 10, 10) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%487, %283), scope: Sequential/Sequential[8]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[0]\n",
      "  %489 : Float(1, 1024, 10, 10) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%488, %284, %285, %286, %287), scope: Sequential/Sequential[8]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[1]\n",
      "  %490 : Float(1, 1024, 10, 10) = onnx::Relu(%489), scope: Sequential/Sequential[8]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[2]\n",
      "  %491 : Float(1, 1024, 10, 10) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%490, %289), scope: Sequential/Sequential[8]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[3]\n",
      "  %492 : Float(1, 1024, 10, 10) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%491, %290, %291, %292, %293), scope: Sequential/Sequential[8]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[4]\n",
      "  %493 : Float(1, 1024, 10, 10) = onnx::Relu(%492), scope: Sequential/Sequential[8]/Sequential[1]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[5]\n",
      "  %494 : Float(1, 2048, 10, 10) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%493, %295), scope: Sequential/Sequential[8]/Sequential[1]/LambdaMap[0]/Sequential[0]/Conv2d[1]\n",
      "  %495 : Float(1, 2048, 10, 10) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%494, %296, %297, %298, %299), scope: Sequential/Sequential[8]/Sequential[1]/LambdaMap[0]/Sequential[0]/BatchNorm2d[2]\n",
      "  %496 : Float(1, 2048, 10, 10) = onnx::Add(%495, %487), scope: Sequential/Sequential[8]/Sequential[1]/LambdaReduce[1]\n",
      "  %497 : Float(1, 2048, 10, 10) = onnx::Relu(%496), scope: Sequential/Sequential[8]/Sequential[1]/ReLU[2]\n",
      "  %498 : Float(1, 1024, 10, 10) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%497, %301), scope: Sequential/Sequential[8]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[0]\n",
      "  %499 : Float(1, 1024, 10, 10) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%498, %302, %303, %304, %305), scope: Sequential/Sequential[8]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[1]\n",
      "  %500 : Float(1, 1024, 10, 10) = onnx::Relu(%499), scope: Sequential/Sequential[8]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[2]\n",
      "  %501 : Float(1, 1024, 10, 10) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%500, %307), scope: Sequential/Sequential[8]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/Conv2d[3]\n",
      "  %502 : Float(1, 1024, 10, 10) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%501, %308, %309, %310, %311), scope: Sequential/Sequential[8]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/BatchNorm2d[4]\n",
      "  %503 : Float(1, 1024, 10, 10) = onnx::Relu(%502), scope: Sequential/Sequential[8]/Sequential[2]/LambdaMap[0]/Sequential[0]/Sequential[0]/ReLU[5]\n",
      "  %504 : Float(1, 2048, 10, 10) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%503, %313), scope: Sequential/Sequential[8]/Sequential[2]/LambdaMap[0]/Sequential[0]/Conv2d[1]\n",
      "  %505 : Float(1, 2048, 10, 10) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%504, %314, %315, %316, %317), scope: Sequential/Sequential[8]/Sequential[2]/LambdaMap[0]/Sequential[0]/BatchNorm2d[2]\n",
      "  %506 : Float(1, 2048, 10, 10) = onnx::Add(%505, %497), scope: Sequential/Sequential[8]/Sequential[2]/LambdaReduce[1]\n",
      "  %507 : Float(1, 2048, 10, 10) = onnx::Relu(%506), scope: Sequential/Sequential[8]/Sequential[2]/ReLU[2]\n",
      "  %508 : Float(1, 2048, 1, 1) = onnx::MaxPool[kernel_shape=[10, 10], pads=[0, 0, 0, 0], strides=[10, 10]](%507), scope: Sequential/AdaptiveConcatPool2d[9]/MyAdaptiveMaxPool2d[mp]/MaxPool2d[p]\n",
      "  %509 : Dynamic = onnx::Pad[mode=constant, pads=[0, 0, 0, 0, 0, 0, 0, 0], value=0](%507), scope: Sequential/AdaptiveConcatPool2d[9]/MyAdaptiveAvgPool2d[ap]/AvgPool2d[p]\n",
      "  %510 : Float(1, 2048, 1, 1) = onnx::AveragePool[kernel_shape=[10, 10], pads=[0, 0, 0, 0], strides=[10, 10]](%509), scope: Sequential/AdaptiveConcatPool2d[9]/MyAdaptiveAvgPool2d[ap]/AvgPool2d[p]\n",
      "  %511 : Float(1, 4096, 1, 1) = onnx::Concat[axis=1](%508, %510), scope: Sequential/AdaptiveConcatPool2d[9]\n",
      "  %512 : Dynamic = onnx::Shape(%511), scope: Sequential/Flatten[10]\n",
      "  %513 : Dynamic = onnx::Slice[axes=[0], ends=[1], starts=[0]](%512), scope: Sequential/Flatten[10]\n",
      "  %514 : Long() = onnx::Squeeze[axes=[0]](%513), scope: Sequential/Flatten[10]\n",
      "  %515 : Long() = onnx::Constant[value={-1}](), scope: Sequential/Flatten[10]\n",
      "  %516 : Dynamic = onnx::Unsqueeze[axes=[0]](%514), scope: Sequential/Flatten[10]\n",
      "  %517 : Dynamic = onnx::Unsqueeze[axes=[0]](%515), scope: Sequential/Flatten[10]\n",
      "  %518 : Dynamic = onnx::Concat[axis=0](%516, %517), scope: Sequential/Flatten[10]\n",
      "  %519 : Float(1, 4096) = onnx::Reshape(%511, %518), scope: Sequential/Flatten[10]\n",
      "  %520 : Dynamic = onnx::Unsqueeze[axes=[2]](%519), scope: Sequential/BatchNorm1d[11]\n",
      "  %521 : Dynamic = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%520, %319, %320, %321, %322), scope: Sequential/BatchNorm1d[11]\n",
      "  %522 : Float(1, 4096) = onnx::Squeeze[axes=[2]](%521), scope: Sequential/BatchNorm1d[11]\n",
      "  %523 : Float(1, 4096), %524 : Dynamic = onnx::Dropout[is_test=1, ratio=0.5](%522), scope: Sequential/Dropout[12]\n",
      "  %525 : Float(1, 512) = onnx::Gemm[alpha=1, beta=1, broadcast=1, transB=1](%523, %324, %325), scope: Sequential/Linear[13]\n",
      "  %526 : Float(1, 512) = onnx::Relu(%525), scope: Sequential/ReLU[14]\n",
      "  %527 : Dynamic = onnx::Unsqueeze[axes=[2]](%526), scope: Sequential/BatchNorm1d[15]\n",
      "  %528 : Dynamic = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%527, %326, %327, %328, %329), scope: Sequential/BatchNorm1d[15]\n",
      "  %529 : Float(1, 512) = onnx::Squeeze[axes=[2]](%528), scope: Sequential/BatchNorm1d[15]\n",
      "  %530 : Float(1, 512), %531 : Dynamic = onnx::Dropout[is_test=1, ratio=0.5](%529), scope: Sequential/Dropout[16]\n",
      "  %532 : Float(1, 2) = onnx::Gemm[alpha=1, beta=1, broadcast=1, transB=1](%530, %331, %332), scope: Sequential/Linear[17]\n",
      "  %dogorcat : Float(1, 2) = onnx::Softmax[axis=1](%532), scope: Sequential/Softmax[18]\n",
      "  return (%dogorcat);\n",
      "}\n",
      "\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/189: Converting Node Type Div\n",
      "2/189: Converting Node Type Unsqueeze\n",
      "3/189: Converting Node Type Conv\n",
      "4/189: Converting Node Type BatchNormalization\n",
      "5/189: Converting Node Type Relu\n",
      "6/189: Converting Node Type MaxPool\n",
      "7/189: Converting Node Type Conv\n",
      "8/189: Converting Node Type BatchNormalization\n",
      "9/189: Converting Node Type Relu\n",
      "10/189: Converting Node Type Conv\n",
      "11/189: Converting Node Type BatchNormalization\n",
      "12/189: Converting Node Type Relu\n",
      "13/189: Converting Node Type Conv\n",
      "14/189: Converting Node Type BatchNormalization\n",
      "15/189: Converting Node Type Conv\n",
      "16/189: Converting Node Type BatchNormalization\n",
      "17/189: Converting Node Type Add\n",
      "18/189: Converting Node Type Relu\n",
      "19/189: Converting Node Type Conv\n",
      "20/189: Converting Node Type BatchNormalization\n",
      "21/189: Converting Node Type Relu\n",
      "22/189: Converting Node Type Conv\n",
      "23/189: Converting Node Type BatchNormalization\n",
      "24/189: Converting Node Type Relu\n",
      "25/189: Converting Node Type Conv\n",
      "26/189: Converting Node Type BatchNormalization\n",
      "27/189: Converting Node Type Add\n",
      "28/189: Converting Node Type Relu\n",
      "29/189: Converting Node Type Conv\n",
      "30/189: Converting Node Type BatchNormalization\n",
      "31/189: Converting Node Type Relu\n",
      "32/189: Converting Node Type Conv\n",
      "33/189: Converting Node Type BatchNormalization\n",
      "34/189: Converting Node Type Relu\n",
      "35/189: Converting Node Type Conv\n",
      "36/189: Converting Node Type BatchNormalization\n",
      "37/189: Converting Node Type Add\n",
      "38/189: Converting Node Type Relu\n",
      "39/189: Converting Node Type Conv\n",
      "40/189: Converting Node Type BatchNormalization\n",
      "41/189: Converting Node Type Relu\n",
      "42/189: Converting Node Type Conv\n",
      "43/189: Converting Node Type BatchNormalization\n",
      "44/189: Converting Node Type Relu\n",
      "45/189: Converting Node Type Conv\n",
      "46/189: Converting Node Type BatchNormalization\n",
      "47/189: Converting Node Type Conv\n",
      "48/189: Converting Node Type BatchNormalization\n",
      "49/189: Converting Node Type Add\n",
      "50/189: Converting Node Type Relu\n",
      "51/189: Converting Node Type Conv\n",
      "52/189: Converting Node Type BatchNormalization\n",
      "53/189: Converting Node Type Relu\n",
      "54/189: Converting Node Type Conv\n",
      "55/189: Converting Node Type BatchNormalization\n",
      "56/189: Converting Node Type Relu\n",
      "57/189: Converting Node Type Conv\n",
      "58/189: Converting Node Type BatchNormalization\n",
      "59/189: Converting Node Type Add\n",
      "60/189: Converting Node Type Relu\n",
      "61/189: Converting Node Type Conv\n",
      "62/189: Converting Node Type BatchNormalization\n",
      "63/189: Converting Node Type Relu\n",
      "64/189: Converting Node Type Conv\n",
      "65/189: Converting Node Type BatchNormalization\n",
      "66/189: Converting Node Type Relu\n",
      "67/189: Converting Node Type Conv\n",
      "68/189: Converting Node Type BatchNormalization\n",
      "69/189: Converting Node Type Add\n",
      "70/189: Converting Node Type Relu\n",
      "71/189: Converting Node Type Conv\n",
      "72/189: Converting Node Type BatchNormalization\n",
      "73/189: Converting Node Type Relu\n",
      "74/189: Converting Node Type Conv\n",
      "75/189: Converting Node Type BatchNormalization\n",
      "76/189: Converting Node Type Relu\n",
      "77/189: Converting Node Type Conv\n",
      "78/189: Converting Node Type BatchNormalization\n",
      "79/189: Converting Node Type Add\n",
      "80/189: Converting Node Type Relu\n",
      "81/189: Converting Node Type Conv\n",
      "82/189: Converting Node Type BatchNormalization\n",
      "83/189: Converting Node Type Relu\n",
      "84/189: Converting Node Type Conv\n",
      "85/189: Converting Node Type BatchNormalization\n",
      "86/189: Converting Node Type Relu\n",
      "87/189: Converting Node Type Conv\n",
      "88/189: Converting Node Type BatchNormalization\n",
      "89/189: Converting Node Type Conv\n",
      "90/189: Converting Node Type BatchNormalization\n",
      "91/189: Converting Node Type Add\n",
      "92/189: Converting Node Type Relu\n",
      "93/189: Converting Node Type Conv\n",
      "94/189: Converting Node Type BatchNormalization\n",
      "95/189: Converting Node Type Relu\n",
      "96/189: Converting Node Type Conv\n",
      "97/189: Converting Node Type BatchNormalization\n",
      "98/189: Converting Node Type Relu\n",
      "99/189: Converting Node Type Conv\n",
      "100/189: Converting Node Type BatchNormalization\n",
      "101/189: Converting Node Type Add\n",
      "102/189: Converting Node Type Relu\n",
      "103/189: Converting Node Type Conv\n",
      "104/189: Converting Node Type BatchNormalization\n",
      "105/189: Converting Node Type Relu\n",
      "106/189: Converting Node Type Conv\n",
      "107/189: Converting Node Type BatchNormalization\n",
      "108/189: Converting Node Type Relu\n",
      "109/189: Converting Node Type Conv\n",
      "110/189: Converting Node Type BatchNormalization\n",
      "111/189: Converting Node Type Add\n",
      "112/189: Converting Node Type Relu\n",
      "113/189: Converting Node Type Conv\n",
      "114/189: Converting Node Type BatchNormalization\n",
      "115/189: Converting Node Type Relu\n",
      "116/189: Converting Node Type Conv\n",
      "117/189: Converting Node Type BatchNormalization\n",
      "118/189: Converting Node Type Relu\n",
      "119/189: Converting Node Type Conv\n",
      "120/189: Converting Node Type BatchNormalization\n",
      "121/189: Converting Node Type Add\n",
      "122/189: Converting Node Type Relu\n",
      "123/189: Converting Node Type Conv\n",
      "124/189: Converting Node Type BatchNormalization\n",
      "125/189: Converting Node Type Relu\n",
      "126/189: Converting Node Type Conv\n",
      "127/189: Converting Node Type BatchNormalization\n",
      "128/189: Converting Node Type Relu\n",
      "129/189: Converting Node Type Conv\n",
      "130/189: Converting Node Type BatchNormalization\n",
      "131/189: Converting Node Type Add\n",
      "132/189: Converting Node Type Relu\n",
      "133/189: Converting Node Type Conv\n",
      "134/189: Converting Node Type BatchNormalization\n",
      "135/189: Converting Node Type Relu\n",
      "136/189: Converting Node Type Conv\n",
      "137/189: Converting Node Type BatchNormalization\n",
      "138/189: Converting Node Type Relu\n",
      "139/189: Converting Node Type Conv\n",
      "140/189: Converting Node Type BatchNormalization\n",
      "141/189: Converting Node Type Add\n",
      "142/189: Converting Node Type Relu\n",
      "143/189: Converting Node Type Conv\n",
      "144/189: Converting Node Type BatchNormalization\n",
      "145/189: Converting Node Type Relu\n",
      "146/189: Converting Node Type Conv\n",
      "147/189: Converting Node Type BatchNormalization\n",
      "148/189: Converting Node Type Relu\n",
      "149/189: Converting Node Type Conv\n",
      "150/189: Converting Node Type BatchNormalization\n",
      "151/189: Converting Node Type Conv\n",
      "152/189: Converting Node Type BatchNormalization\n",
      "153/189: Converting Node Type Add\n",
      "154/189: Converting Node Type Relu\n",
      "155/189: Converting Node Type Conv\n",
      "156/189: Converting Node Type BatchNormalization\n",
      "157/189: Converting Node Type Relu\n",
      "158/189: Converting Node Type Conv\n",
      "159/189: Converting Node Type BatchNormalization\n",
      "160/189: Converting Node Type Relu\n",
      "161/189: Converting Node Type Conv\n",
      "162/189: Converting Node Type BatchNormalization\n",
      "163/189: Converting Node Type Add\n",
      "164/189: Converting Node Type Relu\n",
      "165/189: Converting Node Type Conv\n",
      "166/189: Converting Node Type BatchNormalization\n",
      "167/189: Converting Node Type Relu\n",
      "168/189: Converting Node Type Conv\n",
      "169/189: Converting Node Type BatchNormalization\n",
      "170/189: Converting Node Type Relu\n",
      "171/189: Converting Node Type Conv\n",
      "172/189: Converting Node Type BatchNormalization\n",
      "173/189: Converting Node Type Add\n",
      "174/189: Converting Node Type Relu\n",
      "175/189: Converting Node Type MaxPool\n",
      "176/189: Converting Node Type Pad\n",
      "177/189: Converting Node Type AveragePool\n",
      "178/189: Converting Node Type Concat\n",
      "179/189: Converting Node Type Reshape\n",
      "180/189: Converting Node Type Unsqueeze\n",
      "181/189: Converting Node Type BatchNormalization\n",
      "182/189: Converting Node Type Squeeze\n",
      "183/189: Converting Node Type Gemm\n",
      "184/189: Converting Node Type Relu\n",
      "185/189: Converting Node Type Unsqueeze\n",
      "186/189: Converting Node Type BatchNormalization\n",
      "187/189: Converting Node Type Squeeze\n",
      "188/189: Converting Node Type Gemm\n",
      "189/189: Converting Node Type Softmax\n",
      "Translation to CoreML spec completed. Now compiling the CoreML model.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"dog_vs_cat_image.onnx\"\n",
    "\n",
    "# Convert Pytorch model to onnx model & check if it is convertible\n",
    "onnx_model = check_onnx_compatible(final_model, model_name, sz, input_names=['image'], output_names=['dogorcat'])\n",
    "\n",
    "# Convert onnx model to Apple Core ML\n",
    "mlmodel = convert(onnx.load(model_name), image_input_names = ['image'], mode='classifier', class_labels=\"labels.txt\")\n",
    "mlmodel.author = 'Hung Nguyen'\n",
    "mlmodel.license = 'MIT'\n",
    "mlmodel.short_description = 'This model takes a picture of a dog or cat and predicts its a cat or a dog'\n",
    "mlmodel.input_description['image'] = 'Image of a dog or cat or something else'\n",
    "mlmodel.output_description['dogorcat'] = 'Confidence and label of predicted dog or cat'\n",
    "mlmodel.output_description['classLabel'] = 'Label of predicted dog or cat'\n",
    "\n",
    "mlmodel.save(f'{model_name}.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools\n",
    "\n",
    "model =  coremltools.models.MLModel(f'{model_name}.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Features(dogorcat,classLabel)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method MLModel.visualize_spec of input {\n",
       "  name: \"image\"\n",
       "  shortDescription: \"Image of a dog or cat or something else\"\n",
       "  type {\n",
       "    imageType {\n",
       "      width: 299\n",
       "      height: 299\n",
       "      colorSpace: RGB\n",
       "    }\n",
       "  }\n",
       "}\n",
       "output {\n",
       "  name: \"dogorcat\"\n",
       "  shortDescription: \"Confidence and label of predicted dog or cat\"\n",
       "  type {\n",
       "    dictionaryType {\n",
       "      stringKeyType {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "output {\n",
       "  name: \"classLabel\"\n",
       "  shortDescription: \"Label of predicted dog or cat\"\n",
       "  type {\n",
       "    stringType {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "predictedFeatureName: \"classLabel\"\n",
       "predictedProbabilitiesName: \"dogorcat\"\n",
       "metadata {\n",
       "  shortDescription: \"This model takes a picture of a dog or cat and predicts its a cat or a dog\"\n",
       "  author: \"Hung Nguyen\"\n",
       "  license: \"MIT\"\n",
       "}\n",
       ">"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.visualize_spec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "266px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
